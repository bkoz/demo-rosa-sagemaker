{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "036cfa9e-2fe0-4af4-8cf1-4458e56ff7b2",
   "metadata": {},
   "source": [
    "# Notebook Under Construction\n",
    "\n",
    "This tutorial showed how to train a model for image classification, test it, convert it to the TensorFlow Lite format for on-device applications (such as an image classification app), and perform inference with the TensorFlow Lite model with the Python API.\n",
    "\n",
    "1. Setup\n",
    "1. Load the trained moddel\n",
    "1. Predict on sample data\n",
    "1. Compress model for mobile, embeddded or edge device\n",
    "1. Run TF Lite model\n",
    "1. Predct with compressed model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b8d8cc-690e-40c2-8fdd-756e2e250834",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce85f55-edd9-48c8-9f15-dd310781824f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U pip --quiet\n",
    "!pip install -r ../../requirements.txt --quiet\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential,Model, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout,Activation, Flatten, Conv2D, MaxPool2D\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "print(\"tensorflow version:  \" + tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f00f93-fdf0-4b2d-b203-f01b7ad1a23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this directory is apart of the .gitignore to ensure it is not committed to git\n",
    "%env SCRATCH=../scratch\n",
    "![ -e \"${SCRATCH}\" ] || mkdir -p \"${SCRATCH}\"/model\n",
    "\n",
    "import os\n",
    "scratch_path = os.environ.get('SCRATCH', '../scratch')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a086dcc9-be55-494f-ac85-ff1e085eeda0",
   "metadata": {},
   "source": [
    "# Load the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd445629-984c-48b3-aa92-901bedc9a0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model( scratch_path + '/model/left-right-print-prediction-1.0.0.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a5705b-3ca0-4a8f-8c86-0a0d0102393b",
   "metadata": {},
   "source": [
    "# Compress model for mobile, embedded or edge device with TensorFlow Lite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e3864a-0065-4a6b-9f03-179dc74046c3",
   "metadata": {},
   "source": [
    "TensorFlow Lite is a set of tools that enables on-device machine learning by helping developers run their models on mobile, embedded, and edge devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc24f60-d0fc-47a1-a081-9563b00d6a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the model.\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open(scratch_path + '/model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa10197-3df6-478a-8927-c6b4eeceba92",
   "metadata": {},
   "source": [
    "# Run the TF Lite model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e4279e-7214-44f8-ba7a-b5cd7cfb44f5",
   "metadata": {},
   "source": [
    "You can access the TensorFlow Lite saved model signatures in Python via the tf.lite.Interpreter class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8511907b-fb09-4458-bbe4-6984ff35c2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_MODEL_FILE_PATH = scratch_path + '/model.tflite' # The default path to the saved TensorFlow Lite model\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_path=TF_MODEL_FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95f9666-d34c-473c-9cd1-5ef1ed3a3d74",
   "metadata": {},
   "source": [
    "Print the signatures from the converted model to obtain the names of the inputs (and outputs):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c9b50f-aee3-48b2-a6fd-f1fe9ec48399",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.get_signature_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c80822-6300-406c-bb6c-434c68c59a66",
   "metadata": {},
   "source": [
    "In this example, you have one default signature called serving_default. In addition, the name of the 'inputs' is 'sequential_1_input', while the 'outputs' are called 'outputs'. You can look up these first and last Keras layer names when running Model.summary, as demonstrated earlier in this tutorial.\n",
    "\n",
    "Now you can test the loaded TensorFlow Model by performing inference on a sample image with tf.lite.Interpreter.get_signature_runner by passing the signature name as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd80f78-fd13-4213-98a2-caf55bf3597b",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_lite = interpreter.get_signature_runner('serving_default')\n",
    "classify_lite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5f3502-73f6-4387-9837-6744b868b689",
   "metadata": {},
   "source": [
    "Similar to what you did earlier in the tutorial, you can use the TensorFlow Lite model to classify images that weren't included in the training or validation sets.\n",
    "\n",
    "You have already tensorized that image and saved it as img_array. Now, pass it to the first argument (the name of the 'inputs') of the loaded TensorFlow Lite model (predictions_lite), compute softmax activations, and then print the prediction for the class with the highest computed probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fb51e4-3f3a-4c8a-a822-a2d10d206f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lite = classify_lite(sequential_1=img_array)['outputs']\n",
    "score_lite = tf.nn.softmax(predictions_lite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80811c2d-ba62-47ea-8b3c-f474773ea1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score_lite)], 100 * np.max(score_lite))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b845829-9d62-4b2a-a813-083ba3832c6d",
   "metadata": {},
   "source": [
    "The prediction generated by the lite model should be almost identical to the predictions generated by the original model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ba7d5a-e02e-469f-ab89-882a5f87f193",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(np.abs(predictions - predictions_lite)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0dafa093-6baa-482e-8abc-10f03182c917",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/tutorials/images/classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcd6d68-7675-4c45-a1bc-b0ff54692c70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p38",
   "language": "python",
   "name": "conda_tensorflow2_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
