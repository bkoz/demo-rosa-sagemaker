{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48b3b4cb-27a8-477b-8318-402869526d22",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "Demonstrate using ROSA with AWS SageMaker SDK for machine learning development. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65bd137-2558-42eb-80cb-9625e5325292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO create ODH SageMaker Notebook image\n",
    "!pip install -q -r ../../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0550dea5-7e11-4dc8-a4ae-cdfd9b8a01d8",
   "metadata": {},
   "source": [
    "## Verify your environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b45a176-bb5b-46eb-94fe-623af7101189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the below line to display the values for the Environment Variables. If not set, enter in the notebook image spawner prior to starting the server.\n",
    "#!env | grep 'AWS\\|S3\\|ARN' | sort"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3f377b-7f0e-45f6-9b51-8aad1124b3c9",
   "metadata": {},
   "source": [
    "# Imports\n",
    "\n",
    "Amazon SageMaker Python SDK - is an open source library for training and deploying machine-learned models on Amazon SageMaker. With the SDK, you can train and deploy models using popular deep learning frameworks, algorithms provided by Amazon, or your own algorithms. https://sagemaker.readthedocs.io/en/stable/\n",
    "\n",
    "Boto3 - is the Amazon Web Services (AWS) Software Development Kit (SDK) for Python, which allows Python developers to write software that makes use of services like Amazon S3 and Amazon EC2. Boto3 is maintained and published by Amazon Web Services. https://github.com/boto/boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51367076-037f-431f-bf56-a6887bdccd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import AWS Sagemaker SDK \n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "# for the tf estimator model that is used to train with\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "# import the AWS SDK for python. \n",
    "import boto3\n",
    "\n",
    "# import os for misc. operating system dependent functionality\n",
    "import os\n",
    "\n",
    "# import numpy for common machine learning libraries like scikit-learn and SciPy\n",
    "import numpy as np\n",
    "\n",
    "# import keras for an open-source software library that provides a Python interface for artificial neural networks\n",
    "import keras\n",
    "\n",
    "# this module provide a few toy datasets (already-vectorized, in Numpy format) that can be used for debugging a model or creating simple code\n",
    "from keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f6e673-2ab5-4b56-8ecb-3f1d700e08d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the imported versions\n",
    "print(\"SageMaker \" + sagemaker.__version__)\n",
    "print(\"Boto3 \" + boto3.__version__)\n",
    "print(\"keras \" + keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e8d825-ee7e-49db-9997-8295689eae60",
   "metadata": {},
   "source": [
    "# AWS Configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8e4ab3-3051-4782-996a-d769fd5189b6",
   "metadata": {},
   "source": [
    "## Set your region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950b4d1d-e51c-4236-8a3f-e9316cb11037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# session manages interactions with the Amazon SageMaker APIs and any other AWS services needed.\n",
    "sess = sagemaker.Session(boto3.session.Session(region_name=os.getenv('AWS_DEFAULT_REGION')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc8975b-adc9-4e31-a013-30e6408d16dd",
   "metadata": {},
   "source": [
    "## Set your IAM role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13275bbd-98f5-4842-9b04-7bc987cbc25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a role https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html. if you need to create or find the arn, for example, you'd go to https://us-east-1.console.aws.amazon.com/iamv2\n",
    "# set your IAM role arn for the Execution Role\n",
    "role = os.getenv('EXECUTION_ROLE_ARN')\n",
    "\n",
    "# Uncomment to verify role values\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a04fd42-0a3b-4922-aa4c-4c887360909c",
   "metadata": {},
   "source": [
    "With a known ARN for your role, you can programmatically check the role when running the notebook locally or on SageMaker. Replace RoleName with your known ARN:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d58013-d4f4-4a47-af30-62c2f10d9c5d",
   "metadata": {},
   "source": [
    "## Configure the S3 storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88de76c-7431-4409-82f3-2d9f4ef94408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For S3 Storage\n",
    "# Edit this section using your own credentials\n",
    "# enter your region name\n",
    "s3_region = os.getenv('AWS_DEFAULT_REGION')\n",
    "\n",
    "# enter your S3 endpoint URL\n",
    "s3_endpoint_url = os.getenv('S3_ENDPOINT_URL')\n",
    "\n",
    "# enter your S3 access key ID\n",
    "s3_access_key_id = os.getenv('S3_ACCESS_KEY_ID')\n",
    "\n",
    "# enter your S3 secret access key\n",
    "# TODO make OCP secret\n",
    "# TODO OIDC identity\n",
    "s3_secret_access_key = os.getenv('S3_SECRET_ACCESS_KEY')\n",
    "\n",
    "# enter your S3 bucket name\n",
    "s3_bucket = os.getenv('S3_BUCKET')\n",
    "\n",
    "# configure boto S3 connection\n",
    "s3 = boto3.client('s3',\n",
    "                  s3_region,\n",
    "                  #endpoint_url = s3_endpoint_url,\n",
    "                  aws_access_key_id = s3_access_key_id,\n",
    "                  aws_secret_access_key = s3_secret_access_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c35e50-ee31-4712-9859-3315617f7958",
   "metadata": {},
   "source": [
    "## Test your S3 bucket connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4ca6cd-c8f0-40b0-845b-2a8bde4a5ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncommect to verify S3 bucket connection\n",
    "s3.list_buckets()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368cfdd7-f9a1-41f0-87df-012cea2019ae",
   "metadata": {},
   "source": [
    "# Configure your Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49eb0b70-377a-4815-9108-16b12203f770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train is the data and y_train is the label\n",
    "# x_val is the data and y_val is the label\n",
    "(x_train, y_train), (x_val, y_val) = fashion_mnist.load_data()\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# these paths assume you have a folder 'data' in your bucket\n",
    "training = 'data/training.npz'\n",
    "validation = 'data/validation.npz'\n",
    "s3.upload_file(training, s3_bucket, training)\n",
    "s3.upload_file(validation, s3_bucket, validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc8073d-2ff7-4497-8b41-3e0818767951",
   "metadata": {},
   "source": [
    "### Upload data to your S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35629c9-0cbf-4eed-99c6-a09edb361288",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo $S3_BUCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61324e3b-2f3c-447d-8142-ca88d067ba16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the training path for the data\n",
    "training_input_path = 's3://sagemaker-ocpai/data/training.npz'\n",
    "\n",
    "# set the validation path for the data\n",
    "validation_input_path = 's3://sagemaker-ocpai/data/validation.npz'\n",
    "\n",
    "# Set the location to store the trained model\n",
    "output_path = 's3://sagemaker-ocpai/models/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143c5873-61df-4587-a3cc-86823c43628d",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f363317-1a07-4184-900d-46486c92d28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of parameters https://sagemaker.readthedocs.io/en/stable/frameworks/tensorflow/sagemaker.tensorflow.html\n",
    "# list of instance types https://aws.amazon.com/sagemaker/pricing/\n",
    "\n",
    "tf_estimator = TensorFlow(entry_point='mnist_keras_tf.py', # Path (absolute or relative) to the local Python source file which should be executed as the entry point to training\n",
    "                          role=role,                       # The or the TensorFlowModel\n",
    "                          instance_count=1,                # number of EC2 instances to use\n",
    "                          instance_type='ml.m5.2xlarge',   # Type of EC2 instance to use, for example, ‘ml.c4.xlarge’.\n",
    "                          framework_version='1.15',        # TF version to use for executing the training code\n",
    "                          py_version='py3',                # Python version to use for executing the model training code\n",
    "                          hyperparameters={'epochs': 1},   # hyperparameters used during training\n",
    "                          model_dir=output_path            # S3 location where the checkpoint data and models can be exported during training\n",
    "                          )  \n",
    "\n",
    "                          #image_uri=123.dkr.ecr.us-west-2.amazonaws.com/my-custom-image:1.0 custom-image:latest,\n",
    "                          #distribution,                   # how to run distributed training for data or model parallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57703e87-2c89-4b49-bc61-44078ab7997c",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45b58b7-5d79-4593-a314-6d0a69220962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train! This will pull (once) the SageMaker CPU/GPU container for TensorFlow to your local machine.\n",
    "# Make sure that Docker is running and that docker-compose is installed\n",
    "\n",
    "tf_estimator.fit({'training': training_input_path, 'validation': validation_input_path})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf1d20d-d227-4170-a15d-92320529bc68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "5b3ded1ccb95c1d9bd405e7b823d9e85424cde40fbb5985eb47e999ef50e15b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
